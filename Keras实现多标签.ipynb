{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把一个样本的标签集表示为类标签依赖矩阵。m(i,j)=1,当y(i)=1且y(j)=1；m(i,j)=0,其它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependentMatrix(y):\n",
    "    n = len(y)\n",
    "    m = np.zeros(shape=[n,n])\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if y[i] == 1 and y[j] == 1:\n",
    "                m[i][j] = 1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "data = np.load('AMPs-ML.npz')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train = X_train.shape[0]\n",
    "label_train = np.ndarray([n_train,6,6,1])\n",
    "for i in range(n_train):\n",
    "    label_train[i,:,:,0] = dependentMatrix(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "    chanDim = -1\n",
    "    model1 = Sequential()\n",
    "    model1.add(Conv2D(32,(3,3), padding=\"same\", input_shape=(20,20,3)))\n",
    "    model1.add(Activation(\"relu\"))\n",
    "    model1.add(BatchNormalization(axis=chanDim))\n",
    "    model1.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model1.add(Dropout(0.25))\n",
    "\n",
    "    # (CONV => RELU) * 2 => POOL\n",
    "    model1.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model1.add(Activation(\"relu\"))\n",
    "    model1.add(BatchNormalization(axis=chanDim))\n",
    "    model1.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model1.add(Activation(\"relu\"))\n",
    "    model1.add(BatchNormalization(axis=chanDim))\n",
    "    model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model1.add(Dropout(0.25))\n",
    "\n",
    "    # (CONV => RELU) * 2 => POOL\n",
    "    model1.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model1.add(Activation(\"relu\"))\n",
    "    model1.add(BatchNormalization(axis=chanDim))\n",
    "    model1.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model1.add(Activation(\"relu\"))\n",
    "    model1.add(BatchNormalization(axis=chanDim))\n",
    "    model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model1.add(Dropout(0.25))\n",
    "\n",
    "    # first set of FC => RELU layers\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(1024))\n",
    "    model1.add(Activation(\"relu\"))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Dropout(0.5))\n",
    "    \n",
    "    # second set of FC\n",
    "    model1.add(Dense(2048))\n",
    "    model1.add(Activation(\"relu\"))\n",
    "   # model1.add(BatchNormalization())\n",
    "    #model1.add(Dropout(0.5))\n",
    "    \n",
    "    model2 = Sequential()\n",
    "    model2.add(Conv2D(32,(3,3), padding=\"same\", input_shape=(6,6,1)))\n",
    "    model2.add(Activation(\"relu\"))\n",
    "    model2.add(BatchNormalization(axis=chanDim))\n",
    "    \n",
    "    model2.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model2.add(Activation(\"relu\"))\n",
    "    model2.add(BatchNormalization(axis=chanDim))\n",
    "    \n",
    "    model2.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model2.add(Activation(\"relu\"))\n",
    "    model2.add(BatchNormalization(axis=chanDim))\n",
    "    \n",
    "    model2.add(Flatten())\n",
    "    model2.add(Dense(512))\n",
    "    model2.add(Activation(\"relu\"))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Dropout(0.5))\n",
    "    \n",
    "   \n",
    "    model2.add(Dense(1024))\n",
    "    model2.add(Activation(\"relu\"))\n",
    "    #model2.add(BatchNormalization())\n",
    "    #model2.add(Dropout(0.5))\n",
    "    net = Sequential()\n",
    "    net.add( keras.layers.Concatenate(axis=-1)([model1,model2]))\n",
    "    net = Dense(units=1024, activation=\"relu\")(model)\n",
    "    net = Dropout(rate=0.5)(model)\n",
    "    net = Dense(units=6, activation=\"sigmoid\")\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer concatenate_7 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.engine.sequential.Sequential'>. Full input: [<keras.engine.sequential.Sequential object at 0x0000022886298AC8>, <keras.engine.sequential.Sequential object at 0x00000228868E5B70>]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mE:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m                 \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    473\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[1;32m--> 474\u001b[1;33m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'keras.engine.sequential.Sequential'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-5dacfb20387f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# initiallize the optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mINIT_LR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mINIT_LR\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crosssentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-d04d9259c8e9>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m()\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m#model2.add(Dropout(0.5))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    283\u001b[0m                                  \u001b[1;34m'Received type: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full input: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. All inputs to the layer '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m                                  'should be tensors.')\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer concatenate_7 was called with an input that isn't a symbolic tensor. Received type: <class 'keras.engine.sequential.Sequential'>. Full input: [<keras.engine.sequential.Sequential object at 0x0000022886298AC8>, <keras.engine.sequential.Sequential object at 0x00000228868E5B70>]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-3\n",
    "EPOCHS = 75\n",
    "BS = 32\n",
    "# initiallize the optimizer\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR/EPOCHS)\n",
    "nn = model()\n",
    "nn.compile(loss='binary_crosssentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# compile the model using binary cross-entropy rather than\n",
    "# categorical cross-entropy -- this may seem counterintuitive for\n",
    "# multi-label classification, but keep in mind that the goal here\n",
    "# is to treat each output label as an independent Bernoulli distribution\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "\n",
    "nn.fit([X_train, label_train], y_train,\n",
    "          epochs=20,\n",
    "          batch_size=64,\n",
    "         class_weight=cw,\n",
    "         verbose=0)\n",
    "#score = nn.evaluate(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SmallerVGGNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes, finalAct=\"softmax\"):\n",
    "        # initialize the model along with the input shape to be\n",
    "        # \"channels last\" and the channels dimension itself\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "\n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        # and channels dimension\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "            \n",
    "        # CONV => RELU => POOL\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "            input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        # (CONV => RELU) * 2 => POOL\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # use a *softmax* activation for single-label classification\n",
    "        # and *sigmoid* activation for multi-label classification\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(finalAct))\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('AMPs-ML.npz')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "y1 = y_train[:,0]\n",
    "\n",
    "y1_cate = to_categorical(y1,num_classes=2)\n",
    "sum(y1_cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分成6个2分类预测器，每个预测器预测一个标签\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "INIT_LR = 1e-3\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "y_pred=np.zeros([y_test.shape[0],6])\n",
    "for i in range(6):\n",
    "    y_sub = y_train[:,i]\n",
    "    y_bin = to_categorical(y_sub, num_classes=2)\n",
    "    y_count = sum(y_bin)\n",
    "    cw = {0: 1/(2*y_count[0]), 1: 1/(2*y_count[1])}\n",
    "    model = SmallerVGGNet.build(width=20, height=20, depth=3, classes=2, finalAct='softmax')\n",
    "    opt = Adam(lr=INIT_LR, decay=INIT_LR/EPOCHS)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    print('[INFO] training network for label {}'.format(i))\n",
    "    model.fit(X_train,y_bin, batch_size=BS, epochs=20,\n",
    "             class_weight=cw, verbose=0)\n",
    "    y_pred[:,i] = model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "print(\"the subset accuracy: {}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"hamming loss: {}\".format(hamming_loss(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test[:,5],y_pred[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#同时预测6个标签\n",
    "import numpy as np\n",
    "data = np.load('AMPs-ML.npz')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "INIT_LR = 1e-3\n",
    "EPOCHS = 75\n",
    "BS = 32\n",
    "model = SmallerVGGNet.build(width=20, height=20, depth=3, classes=6, finalAct=\"sigmoid\")\n",
    "\n",
    "# initiallize the optimizer\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR/EPOCHS)\n",
    "w = sum(y_train)\n",
    "cw = {}\n",
    "for i in range(6):\n",
    "    cw[i] = 1/(6*w[i])\n",
    "# compile the model using binary cross-entropy rather than\n",
    "# categorical cross-entropy -- this may seem counterintuitive for\n",
    "# multi-label classification, but keep in mind that the goal here\n",
    "# is to treat each output label as an independent Bernoulli distribution\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=64,\n",
    "         class_weight=cw,\n",
    "         verbose=0)\n",
    "score = model.evaluate(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = model.predict(X_test)\n",
    "#print(\"the subset accuracy: {}\".format(accuracy_score(y_test,p)))\n",
    "#print(\"hamming loss: {}\".format(hamming_loss(y_test,p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=dependentMatrix(y_test[-2])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(923, 6, 6, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(923, 20, 20, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
