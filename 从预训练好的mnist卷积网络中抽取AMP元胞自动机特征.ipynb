{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入库及定义共享函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.layers.normalization import local_response_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络\n",
    "#net trained by convnet-mnist\n",
    "def convnet_mnist():\n",
    "    net = input_data(shape=[None,28,28,1], name='input')\n",
    "    net = conv_2d(net, 32,3, activation='relu', regularizer='L2')\n",
    "    net = max_pool_2d(net,2)\n",
    "    net = local_response_normalization(net)\n",
    "    net = conv_2d(net,64,3, activation='relu', regularizer='L2')\n",
    "    net = max_pool_2d(net,2)\n",
    "    net = local_response_normalization(net)\n",
    "    net = fully_connected(net, 128, activation='tanh')\n",
    "    net = dropout(net, 0.8)\n",
    "    net = fully_connected(net, 256, activation='tanh',name='feature')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络\n",
    "#net trained by cifar10-convnet-mnist\n",
    "# Convolutional network building\n",
    "def cifar10_convnet_mnist():\n",
    "    network = input_data(shape=[None, 28, 28, 1])\n",
    "    network = conv_2d(network, 32, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 2)\n",
    "    network = dropout(network, 0.75)\n",
    "    network = conv_2d(network, 64, 3, activation='relu')\n",
    "    network = conv_2d(network, 64, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 2)\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, 512, activation='relu')\n",
    "        \n",
    "    #network = dropout(network, 0.5)\n",
    "    #network = fully_connected(network, 6, activation='softmax',restore=False)\n",
    "    #network = regression(network, optimizer='adam',\n",
    "    #                     loss='categorical_crossentropy',\n",
    "    #                    learning_rate=0.001)\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把抽取的特征写入到arff格式的文件\n",
    "# arffname: arff file's name\n",
    "# features: 抽取出的特征\n",
    "# label：样本标签（0或1）\n",
    "# filemodel：文件读写模式，a,a+,w,r等等\n",
    "def writeOneClassFeaturesToArffFile(arffame, features, label, filemodel):\n",
    "    num_samples = len(features)\n",
    "    num_features = len(features[0])\n",
    "    arff_file = open(arffname,filemodel)\n",
    "    \n",
    "    if filemodel == 'w':\n",
    "\n",
    "        arff_file.write('@relation relationship\\n')\n",
    "\n",
    "        for i in range(1,num_features+1):\n",
    "            line = '@attribute ' + 'Att' + str(i) + ' numeric\\n'\n",
    "            arff_file.write(line)\n",
    "\n",
    "        arff_file.write('@attribute class {0,1}\\n')\n",
    "        arff_file.write('@data\\n\\n')\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        line = []\n",
    "        for f in features[i]:\n",
    "            line.append(str(f))\n",
    "        \n",
    "        line.append(str(label)) \n",
    "        arff_file.write(\",\".join(line))\n",
    "        arff_file.write('\\n')\n",
    "    arff_file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从图像读写数据\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "def loadOneClassImageArray(filepath,num_feature, label):\n",
    "    files = os.listdir(filepath)\n",
    "    N = len(files)\n",
    "    X = np.ndarray((N,num_feature),dtype=np.float32)\n",
    "    \n",
    "    i = 0\n",
    "    for file in files:\n",
    "        k = file.index('.')\n",
    "        key = file[:k]\n",
    "        fn = os.path.join(filepath,file)\n",
    "        img = Image.open(fn,\"r\")\n",
    "        m = np.array(img)\n",
    "        m = m.reshape((1,num_feature))\n",
    "        X[i] = m\n",
    "        \n",
    "        i = i + 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从预训练的网络抽取6个活性的抗菌肽CA特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepareDataset import load_data\n",
    "X,Y = load_data('e:/repoes/ampnet/data/img_60/', 'e:/repoes/ampnet/data/benchmark_60_Targets.json')\n",
    "X = X.reshape((-1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net trained by convnet-mnist\n",
    "net = convnet_mnist()\n",
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.load('e:/repoes/ampnet/model/convnet_mnist', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽取特征，写入文件\n",
    "features=model.predict(X)\n",
    "arff_file = open('amp_convnet_mnist_features.arff','w')\n",
    "arff_file.write('@relation relationship\\n')\n",
    "for i in range(1,257):\n",
    "    line = '@attribute ' + 'Att' + str(i) + ' numeric\\n'\n",
    "    arff_file.write(line)\n",
    "arff_file.write('@attribute class {0,1}\\n')\n",
    "arff_file.write('@data\\n\\n')\n",
    "\n",
    "for i in range(len(X)):\n",
    "    line = []\n",
    "    for f in features[i]:\n",
    "        line.append(str(f))\n",
    "    for y in Y[i]:\n",
    "        line.append(str(int(y))) \n",
    "    arff_file.write(\",\".join(line))\n",
    "    arff_file.write('\\n')\n",
    "arff_file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net trained by cifar10-convnet-mnist\n",
    "# Real-time data preprocessing\n",
    "# Convolutional network building\n",
    "network = cifar10_convnet_mnist()\n",
    "# Train using classifier\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
    "model.load('e:/repoes/ampnet/model/cifar10_cnn_mnist', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=model.predict(X)\n",
    "arff_file = open('amp_cifa10_cnn_mnist_features.arff','w')\n",
    "arff_file.write('@relation relationship\\n')\n",
    "for i in range(1,513):\n",
    "    line = '@attribute ' + 'Att' + str(i) + ' numeric\\n'\n",
    "    arff_file.write(line)\n",
    "arff_file.write('@attribute class {0,1}\\n')\n",
    "arff_file.write('@data\\n\\n')\n",
    "\n",
    "for i in range(len(X)):\n",
    "    line = []\n",
    "    for f in features[i]:\n",
    "        line.append(str(f))\n",
    "    for y in Y[i]:\n",
    "        line.append(str(int(y))) \n",
    "    arff_file.write(\",\".join(line))\n",
    "    arff_file.write('\\n')\n",
    "arff_file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 从预训练的网络抽取正样本抗菌肽（AMPs）A和负样本非抗菌肽（notAMPs）的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "INFO:tensorflow:Restoring parameters from e:/repoes/ampnet/model/cifar10_cnn_mnist\n"
     ]
    }
   ],
   "source": [
    "network = cifar10_convnet_mnist()\n",
    "# Train using classifier\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
    "model.load('e:/repoes/ampnet/model/cifar10_cnn_mnist', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3fc93f891c0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#notampX = ampX.reshape((-1,28,28,1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#features2 = model.predict(notampX)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mwriteOneClassFeaturesToArffFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marffname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'features2' is not defined"
     ]
    }
   ],
   "source": [
    "# 抽取特征，写入文件\n",
    "#ampX = loadOneClassImageArray('e:/repoes/ampnet/data/img/AMPs_50',784,1)\n",
    "#ampX = ampX.reshape((-1,28,28,1))\n",
    "#features1 = model.predict(ampX)\n",
    "arffname = 'e:/repoes/ampnet/amp_and_notamp.arff'\n",
    "writeOneClassFeaturesToArffFile(arffname, features1, 1, 'w' )\n",
    "\n",
    "notampX = loadOneClassImageArray('e:/repoes/ampnet/data/img/notAMPs_50',784,1)\n",
    "notampX = ampX.reshape((-1,28,28,1))\n",
    "features2 = model.predict(notampX)\n",
    "writeOneClassFeaturesToArffFile(arffname, features2, 0, 'a' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
