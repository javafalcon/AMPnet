{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n",
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import tflearn.variables as va\n",
    "\n",
    "# Loading MNIST dataset\n",
    "import tflearn.datasets.mnist as mnist\n",
    "trainX, trainY, testX, testY = mnist.load_data(one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.15885\u001b[0m\u001b[0m | time: 146.978s\n",
      "| Optimizer | epoch: 001 | loss: 0.15885 - Summaries/acc: 0.9516 -- iter: 54912/55000\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.15734\u001b[0m\u001b[0m | time: 152.292s\n",
      "| Optimizer | epoch: 001 | loss: 0.15734 - Summaries/acc: 0.9517 | val_loss: 0.11586 - val_acc: 0.9650 -- iter: 55000/55000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Define a dnn using Tensorflow\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    # Model variables\n",
    "    X = tf.placeholder(\"float\", [None, 784])\n",
    "    Y = tf.placeholder(\"float\", [None, 10])\n",
    "\n",
    "    # Using TFLearn wrappers for network building\n",
    "    net = tf.reshape(X, [-1, 28, 28, 1])\n",
    "    net = tflearn.conv_2d(net, 32, 3, activation='relu')\n",
    "    net = tflearn.max_pool_2d(net, 2)\n",
    "    net = tflearn.local_response_normalization(net)\n",
    "    net = tflearn.dropout(net, 0.8)\n",
    "    net = tflearn.conv_2d(net, 64, 3, activation='relu')\n",
    "    net = tflearn.max_pool_2d(net, 2)\n",
    "    net = tflearn.local_response_normalization(net)\n",
    "    net = tflearn.dropout(net, 0.8)\n",
    "    net = tflearn.fully_connected(net, 128, activation='tanh')\n",
    "    net = tflearn.dropout(net, 0.8)\n",
    "    #net = tflearn.fully_connected(net, 256, activation='tanh')\n",
    "    #net = tflearn.dropout(net, 0.8)\n",
    "    net = tflearn.fully_connected(net, 10, activation='linear')\n",
    "    \n",
    "    with tf.name_scope('Summaries'):\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=net,labels=Y))\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "        accuracy = tf.reduce_mean(\n",
    "            tf.cast(tf.equal(tf.argmax(net, 1), tf.argmax(Y, 1)), tf.float32),\n",
    "            name=\"acc\")\n",
    "\n",
    "    # construct two varaibles to add as additional \"valiation monitors\"\n",
    "    # these varaibles are evaluated each time validation happens (eg at a snapshot)\n",
    "    # and the results are summarized and output to the tensorboard events file,\n",
    "    # together with the accuracy and loss plots.\n",
    "    #\n",
    "    # Here, we generate a dummy variable given by the sum over the current\n",
    "    # network tensor, and a constant variable.  In practice, the validation\n",
    "    # monitor may present useful information, like confusion matrix\n",
    "    # entries, or an AUC metric.\n",
    "    #with tf.name_scope('CustomMonitor'):\n",
    "    #    test_var = tf.reduce_sum(tf.cast(net, tf.float32), name=\"test_var\")\n",
    "    #    test_const = tf.constant(32.0, name=\"custom_constant\")\n",
    "        # Define a train op\n",
    "    trainop = tflearn.TrainOp(loss=loss, optimizer=optimizer,\n",
    "                           # validation_monitors=[test_var, test_const],\n",
    "                            metric=accuracy, batch_size=128)\n",
    "\n",
    "    # Tensorboard logs stored in /tmp/tflearn_logs/. Using verbose level 2.\n",
    "    trainer = tflearn.Trainer(train_ops=trainop,\n",
    "                              tensorboard_dir='/tmp/tflearn_logs/',\n",
    "                              tensorboard_verbose=2)\n",
    "    # Training for 10 epochs.\n",
    "    trainer.fit({X: trainX, Y: trainY}, val_feed_dicts={X: testX, Y: testY},\n",
    "                n_epoch=1, show_metric=True, run_id='Summaries_example')\n",
    "\n",
    "    # Run the following command to start tensorboard:\n",
    "    # >> tensorboard /tmp/tflearn_logs/\n",
    "# Navigate with your web browser to http://0.0.0.0:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testY[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: 7EP0AW\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name acc_0/ (raw) is illegal; using acc_0/__raw_ instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name acc_0/ (raw) is illegal; using acc_0/__raw_ instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Training samples: 55000\n",
      "Validation samples: 10000\n",
      "--\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tag: acc:0 cannot be found in summaries list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d71fe0d33001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Training for 10 epochs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     trainer.fit({X: trainX, Y: trainY}, val_feed_dicts={X: testX, Y: testY},\n\u001b[0;32m---> 39\u001b[0;31m n_epoch=1, show_metric=True)\n\u001b[0m",
      "\u001b[0;32m~/software/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                                        \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0msnapshot_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                                                        \u001b[0msnapshot_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                                                        show_metric)\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                             \u001b[0;31m# Update training state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tflearn/helpers/trainer.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, training_step, snapshot_epoch, snapshot_step, show_metric)\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0msname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_summ_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m             self.acc_value = summaries.get_value_from_summary_string(\n\u001b[0;32m--> 829\u001b[0;31m                 sname, train_summ_str)\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_status\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tflearn/summaries.py\u001b[0m in \u001b[0;36mget_value_from_summary_string\u001b[0;34m(tag, summary_str)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tag: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" cannot be found in summaries list.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tag: acc:0 cannot be found in summaries list."
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "\n",
    "    # Model variables\n",
    "    X = tf.placeholder(\"float\", [None, 784])\n",
    "    Y = tf.placeholder(\"float\", [None, 10])\n",
    "\n",
    "    W1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "    W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "    W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "    b1 = tf.Variable(tf.random_normal([256]))\n",
    "    b2 = tf.Variable(tf.random_normal([256]))\n",
    "    b3 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "    # Multilayer perceptron\n",
    "    def dnn(x):\n",
    "        x = tf.nn.tanh(tf.add(tf.matmul(x, W1), b1))\n",
    "        x = tf.nn.tanh(tf.add(tf.matmul(x, W2), b2))\n",
    "        x = tf.add(tf.matmul(x, W3), b3)\n",
    "        return x\n",
    "\n",
    "    net = dnn(X)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=net, labels=Y))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "    accuracy = tf.reduce_mean(\n",
    "        tf.cast(tf.equal(tf.argmax(net, 1), tf.argmax(Y, 1)), tf.float32),\n",
    "        name='acc')\n",
    "\n",
    "    # Using TFLearn Trainer\n",
    "    # Define a training op (op for backprop, only need 1 in this model)\n",
    "    trainop = tflearn.TrainOp(loss=loss, optimizer=optimizer,\n",
    "                              metric=accuracy, batch_size=128)\n",
    "\n",
    "    # Create Trainer, providing all training ops. Tensorboard logs stored\n",
    "    # in /tmp/tflearn_logs/. It is possible to change verbose level for more\n",
    "    # details logs about gradients, variables etc...\n",
    "    trainer = tflearn.Trainer(train_ops=trainop, tensorboard_verbose=0)\n",
    "    # Training for 10 epochs.\n",
    "    trainer.fit({X: trainX, Y: trainY}, val_feed_dicts={X: testX, Y: testY},\n",
    "n_epoch=1, show_metric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
