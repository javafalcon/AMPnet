{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入库及定义共享函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义网络\n",
    "#net trained by convnet-mnist\n",
    "def convnet_mnist():\n",
    "    net = input_data(shape=[None,28,28,1], name='input')\n",
    "    net = conv_2d(net, 32,3, activation='relu', regularizer='L2')\n",
    "    net = max_pool_2d(net,2)\n",
    "    net = local_response_normalization(net)\n",
    "    net = conv_2d(net,64,3, activation='relu', regularizer='L2')\n",
    "    net = max_pool_2d(net,2)\n",
    "    net = local_response_normalization(net)\n",
    "    net = fully_connected(net, 128, activation='tanh')\n",
    "    net = dropout(net, 0.8)\n",
    "    net = fully_connected(net, 256, activation='tanh',name='feature')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义网络\n",
    "#net trained by cifar10-convnet-mnist\n",
    "# Convolutional network building\n",
    "def cifar10_convnet_mnist():\n",
    "    network = input_data(shape=[None, 28, 28, 1])\n",
    "    network = conv_2d(network, 32, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 2)\n",
    "    network = dropout(network, 0.75)\n",
    "    network = conv_2d(network, 64, 3, activation='relu')\n",
    "    network = conv_2d(network, 64, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 2)\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, 512, activation='relu')\n",
    "        \n",
    "    #network = dropout(network, 0.5)\n",
    "    #network = fully_connected(network, 6, activation='softmax',restore=False)\n",
    "    #network = regression(network, optimizer='adam',\n",
    "    #                     loss='categorical_crossentropy',\n",
    "    #                    learning_rate=0.001)\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把特征向量写入到arff格式的文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把抽取的特征写入到arff格式的文件<br>\n",
    "arffname: arff file's name<br>\n",
    "features: 抽取出的特征<br>\n",
    "label：样本标签（0或1）<br>\n",
    "filemodel：文件读写模式，a,a+,w,r等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeOneClassFeaturesToArffFile(arffame, features, label, filemodel):\n",
    "    num_samples = len(features)\n",
    "    num_features = len(features[0])\n",
    "    arff_file = open(arffname,filemodel)\n",
    "    \n",
    "    if filemodel == 'w':\n",
    "\n",
    "        arff_file.write('@relation relationship\\n')\n",
    "\n",
    "        for i in range(1,num_features+1):\n",
    "            line = '@attribute ' + 'Att' + str(i) + ' numeric\\n'\n",
    "            arff_file.write(line)\n",
    "\n",
    "        arff_file.write('@attribute class {0,1}\\n')\n",
    "        arff_file.write('@data\\n\\n')\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        line = []\n",
    "        for f in features[i]:\n",
    "            line.append(str(f))\n",
    "        \n",
    "        line.append(str(label)) \n",
    "        arff_file.write(\",\".join(line))\n",
    "        arff_file.write('\\n')\n",
    "    arff_file.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从保存图像的文件夹中读入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从图像读入数据。<br>\n",
    "filepath --保存每个样本序列CA图像的文件夹路径。在此路径下有N个序列的CA图像<br>\n",
    "num_feature --图像行*列的值<br>\n",
    "label --在该文件夹下所保存的样本的标记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "def loadOneClassImageArray(filepath,num_feature):\n",
    "    files = os.listdir(filepath)\n",
    "    N = len(files)\n",
    "    X = np.ndarray((N,num_feature),dtype=np.float32)\n",
    "    \n",
    "    i = 0\n",
    "    for file in files:\n",
    "        k = file.index('.')\n",
    "        key = file[:k]\n",
    "        fn = os.path.join(filepath,file)\n",
    "        img = Image.open(fn,\"r\")\n",
    "        m = np.array(img)\n",
    "        m = m.reshape((1,num_feature))\n",
    "        X[i] = m\n",
    "        \n",
    "        i = i + 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入json文件中的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 从json格式文件中载入数据\n",
    "import numpy as np\n",
    "def loadJsonData(file):\n",
    "    X = []\n",
    "    for line in open(file,'r'):\n",
    "        line = line.replace(\"\\n\",\"\")\n",
    "        x = []\n",
    "        for xx in line.split(\",\"):\n",
    "            x.append(xx)\n",
    "        X.append(x)\n",
    "    return np.array(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从预训练的网络抽取6个活性的抗菌肽CA特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prepareDataset import load_data\n",
    "X,Y = load_data('e:/repoes/ampnet/data/img_60/', 'e:/repoes/ampnet/data/benchmark_60_Targets.json')\n",
    "X = X.reshape((-1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# net trained by convnet-mnist\n",
    "net = convnet_mnist()\n",
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.load('e:/repoes/ampnet/model/convnet_mnist', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 抽取特征，写入文件\n",
    "features=model.predict(X)\n",
    "arff_file = open('amp_convnet_mnist_features.arff','w')\n",
    "arff_file.write('@relation relationship\\n')\n",
    "for i in range(1,257):\n",
    "    line = '@attribute ' + 'Att' + str(i) + ' numeric\\n'\n",
    "    arff_file.write(line)\n",
    "arff_file.write('@attribute class {0,1}\\n')\n",
    "arff_file.write('@data\\n\\n')\n",
    "\n",
    "for i in range(len(X)):\n",
    "    line = []\n",
    "    for f in features[i]:\n",
    "        line.append(str(f))\n",
    "    for y in Y[i]:\n",
    "        line.append(str(int(y))) \n",
    "    arff_file.write(\",\".join(line))\n",
    "    arff_file.write('\\n')\n",
    "arff_file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#net trained by cifar10-convnet-mnist\n",
    "# Real-time data preprocessing\n",
    "# Convolutional network building\n",
    "network = cifar10_convnet_mnist()\n",
    "# Train using classifier\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
    "model.load('e:/repoes/ampnet/model/cifar10_cnn_mnist', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=model.predict(X)\n",
    "arff_file = open('amp_cifa10_cnn_mnist_features.arff','w')\n",
    "arff_file.write('@relation relationship\\n')\n",
    "for i in range(1,513):\n",
    "    line = '@attribute ' + 'Att' + str(i) + ' numeric\\n'\n",
    "    arff_file.write(line)\n",
    "arff_file.write('@attribute class {0,1}\\n')\n",
    "arff_file.write('@data\\n\\n')\n",
    "\n",
    "for i in range(len(X)):\n",
    "    line = []\n",
    "    for f in features[i]:\n",
    "        line.append(str(f))\n",
    "    for y in Y[i]:\n",
    "        line.append(str(int(y))) \n",
    "    arff_file.write(\",\".join(line))\n",
    "    arff_file.write('\\n')\n",
    "arff_file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 从预训练的网络抽取正样本抗菌肽（AMPs）A和负样本非抗菌肽（notAMPs）的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "#network = cifar10_convnet_mnist()\n",
    "network = convnet_mnist()\n",
    "# Train using classifier\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
    "model.load('e:/repoes/ampnet/model/convnet_mnist', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 抽取特征，写入文件\n",
    "#ampX = loadOneClassImageArray('e:/repoes/ampnet/data/img/AMPs_50',784)\n",
    "ampX = loadJsonData(\"E:\\\\Repoes\\\\AMPnet\\\\data\\\\AMPs_50_CA_array.json\")\n",
    "ampX = ampX.reshape((-1,28,28,1))\n",
    "features1 = model.predict(ampX)\n",
    "arffname = 'e:/repoes/ampnet/amp_and_notamp_alnex.arff'\n",
    "writeOneClassFeaturesToArffFile(arffname, features1, 1, 'w' )\n",
    "\n",
    "#notampX = loadOneClassImageArray('e:/repoes/ampnet/data/img/notAMPs_50',784)\n",
    "notampX = loadJsonData(\"E:\\\\Repoes\\\\AMPnet\\\\data\\\\notAMPs_50_CA_array.json\")\n",
    "notampX = ampX.reshape((-1,28,28,1))\n",
    "features2 = model.predict(notampX)\n",
    "writeOneClassFeaturesToArffFile(arffname, features2, 0, 'a' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from tflearn.data_utils import shuffle, to_categorical\n",
    "\n",
    "data,meta = arff.loadarff('e:/repoes/ampnet/amp_and_notamp.arff')\n",
    "n = len(data)\n",
    "X = np.ndarray((n,512))\n",
    "Y = np.zeros(n)\n",
    "for i in range(n):\n",
    "    d = data[i]\n",
    "    for j in range(512):\n",
    "        X[i][j] = float(d[j])\n",
    "    Y[i] = int(d[-1])\n",
    "    \n",
    "X,Y = shuffle(X,Y)\n",
    "Y = to_categorical(Y,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildnet():\n",
    "    net = input_data(shape=[None, 512])\n",
    "    net = fully_connected(net, 2, activation='softmax')\n",
    "    reg = regression(net, optimizer='adam',\n",
    "                           loss='categorical_crossentropy',\n",
    "                           learning_rate=0.001)\n",
    "    model = tflearn.DNN(reg)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, auc, roc_curve\n",
    "import tensorflow as tf\n",
    "loo = LeaveOneOut()\n",
    "y_pred = np.zeros((1600,2))\n",
    "for train_index, test_index in loo.split(X):\n",
    "    print(\"\\r In predicting {}\".format(test_index))\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    tf.reset_default_graph()\n",
    "    model = buildnet()\n",
    "    model.fit(X_train, y_train, n_epoch=10, shuffle=True,\n",
    "             show_metric=True, batch_size=64, snapshot_step=100,\n",
    "             snapshot_epoch=False)\n",
    "    y_pred[test_index] = model.predict(X_test)\n",
    "    \n",
    "accuracy = accuracy_score(y,y_pred)\n",
    "fpr,tpr,thresholds = roc_curve(y,y_pred,pos_label=1)\n",
    "area = auc(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 从预训练的网络中抽取HMMer的profile特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入HMMER执行jackhmmer后产生的chk-1文件的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 每个序列取前50个氨基酸（共50*20=1000个特征），如果序列长度不足50，则补0\n",
    "# 如果序列长度大于50，则截取前50个氨基酸\n",
    "def load_hmm_prof():\n",
    "    files = ['e:/repoes/ampnet/data/benchmark/AMPs_50_hmm_profil.json',\n",
    "         'e:/repoes/ampnet/data/benchmark/notAMPs_50_hmm_profil.json']\n",
    "    N = 1000\n",
    "    X = np.ndarray((1600,N))\n",
    "    y = np.ones(1600)\n",
    "    y[800:] = 0\n",
    "    k = 0\n",
    "    for f in files:\n",
    "        fr = open(f,'r')\n",
    "        p = json.load(fr)\n",
    "        for key in p.keys():\n",
    "            ary = p[key]\n",
    "            c = len(ary)\n",
    "            if c < N:\n",
    "                X[k][:c] = ary\n",
    "                X[k][c:] = 0\n",
    "            elif c == N:\n",
    "                X[k] = ary\n",
    "            else:\n",
    "                X[k] = ary[:N]\n",
    "            k += 1\n",
    "        fr.close()\n",
    "        \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 抽取特征，写入文件\n",
    "#ampX = loadOneClassImageArray('e:/repoes/ampnet/data/img/AMPs_50',784)\n",
    "X,y = load_hmm_prof()\n",
    "X = X.reshape((-1,50,20,1))\n",
    "features1 = model.predict(ampX)\n",
    "arffname = 'e:/repoes/ampnet/amp_and_notamp_alnex.arff'\n",
    "writeOneClassFeaturesToArffFile(arffname, features1, 1, 'w' )\n",
    "\n",
    "#notampX = loadOneClassImageArray('e:/repoes/ampnet/data/img/notAMPs_50',784)\n",
    "notampX = loadJsonData(\"E:\\\\Repoes\\\\AMPnet\\\\data\\\\notAMPs_50_CA_array.json\")\n",
    "notampX = ampX.reshape((-1,28,28,1))\n",
    "features2 = model.predict(notampX)\n",
    "writeOneClassFeaturesToArffFile(arffname, features2, 0, 'a' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "89px",
    "width": "161px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
