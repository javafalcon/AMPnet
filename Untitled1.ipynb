{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "import tensorflow as tf\n",
    "from tflearn.data_utils import shuffle, to_categorical\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.metrics import accuracy_score, auc, roc_curve, matthews_corrcoef\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('AMPs-ML.npz')\n",
    "X = data['X']\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_one_hot(y):\n",
    "    row, col = y.shape\n",
    "    y_ = np.ones(shape=(row,2*col),dtype=np.float32)\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            if y[i,j] == 1:\n",
    "                y_[i,j*2], y_[i, j*2+1] = 1, 0\n",
    "            else:\n",
    "                y_[i,j*2], y_[i, j*2+1] = 0, 1\n",
    "    return y_\n",
    "\n",
    "def decode_one_hot(y):\n",
    "    row,col = y.shape\n",
    "    y_ = np.zeros(shape=(row, col//2), dtype=np.float32)\n",
    "    for i in range(row):\n",
    "        for j in range(col//2):\n",
    "            if  y[i, j*2]  >  y[i,j*2+1]:\n",
    "                y_[i,j] = 1\n",
    "            else:\n",
    "                y_[i,j] = 0\n",
    "    return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0Testing loss=0.11509974\n",
      "Iter 1Testing loss=0.11369845\n",
      "Iter 2Testing loss=0.11234683\n",
      "Iter 3Testing loss=0.1110292\n",
      "Iter 4Testing loss=0.10973446\n",
      "Iter 5Testing loss=0.108453296\n",
      "Iter 6Testing loss=0.10717961\n",
      "Iter 7Testing loss=0.10590987\n",
      "Iter 8Testing loss=0.10464279\n",
      "Iter 9Testing loss=0.10338008\n"
     ]
    }
   ],
   "source": [
    "from nets import CNNnet\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                 X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "M = X_test.shape[0]\n",
    "pred_prob = np.zeros([M,6])\n",
    "\n",
    "s = np.sum(y_train, axis=0)\n",
    "w = s/np.sum(s)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "y_train_one_hot = encode_one_hot(y_train)\n",
    "N = X_train.shape[0]\n",
    "\n",
    "XX = tf.placeholder(\"float\",[None, 20, 20, 3])\n",
    "Y1 = tf.placeholder(\"float\",[None,2])\n",
    "Y2 = tf.placeholder(\"float\",[None,2])\n",
    "Y3 = tf.placeholder(\"float\",[None,2])\n",
    "Y4 = tf.placeholder(\"float\",[None,2])\n",
    "Y5 = tf.placeholder(\"float\",[None,2])\n",
    "Y6 = tf.placeholder(\"float\",[None,2])\n",
    "# Using TFLearn wrappers for network building\n",
    "network = conv_2d(XX, 96, 11, strides=4, activation='relu')\n",
    "network = max_pool_2d(network, 3, strides=2)#[-1,10,10,96]\n",
    "network = local_response_normalization(network)\n",
    "network = conv_2d(network, 256, 5, activation='relu')\n",
    "network = max_pool_2d(network, 3, strides=2)#[-1,5,5,256]\n",
    "network = local_response_normalization(network)\n",
    "network = conv_2d(network, 384, 3, activation='relu')\n",
    "network = conv_2d(network, 384, 3, activation='relu')\n",
    "network = conv_2d(network, 256, 3, activation='relu')\n",
    "network = max_pool_2d(network, 3, strides=2)#[-1,3,3,256]\n",
    "network = local_response_normalization(network)\n",
    "network = fully_connected(network, 4096, activation='tanh')\n",
    "network = dropout(network, 0.5)\n",
    "\n",
    "network1 = fully_connected(network, 4096, activation='tanh')\n",
    "network1 = dropout(network1, 0.5)    \n",
    "network1 = fully_connected(network1, 2, activation='softmax')\n",
    "\n",
    "network2 = fully_connected(network, 4096, activation='tanh')\n",
    "network2 = dropout(network2, 0.5)\n",
    "network2 = fully_connected(network2, 2, activation='softmax')\n",
    "\n",
    "network3 = fully_connected(network, 4096, activation='tanh')\n",
    "network3 = dropout(network3, 0.5)\n",
    "network3 = fully_connected(network3, 2, activation='softmax')\n",
    "\n",
    "network4 = fully_connected(network, 4096, activation='tanh')\n",
    "network4 = dropout(network4, 0.5)\n",
    "network4 = fully_connected(network4, 2, activation='softmax')\n",
    "\n",
    "network5 = fully_connected(network, 4096, activation='tanh')\n",
    "network5 = dropout(network5, 0.5)\n",
    "network5 = fully_connected(network5, 2, activation='softmax')\n",
    "\n",
    "network6 = fully_connected(network, 4096, activation='tanh')\n",
    "network6 = dropout(network6, 0.5)\n",
    "network6 = fully_connected(network6, 2, activation='softmax')\n",
    "\n",
    "loss1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=network1, labels=Y1))\n",
    "loss2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=network2, labels=Y2))\n",
    "loss3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=network3, labels=Y3))\n",
    "loss4 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=network4, labels=Y4))\n",
    "loss5 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=network5, labels=Y5))\n",
    "loss6 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=network6, labels=Y6))\n",
    "\n",
    "loss = (loss1*w[0] + loss2* w[1]+ loss3*w[2] + loss4*w[3] + loss5*w[4] + loss6*w[5])/6\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(loss)\n",
    "\n",
    "pred_label = tf.concat([network1,network2,network3,network4,network5,network6],1)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    batch_size = 64\n",
    "\n",
    "    for epoch in range(10):\n",
    "        n_batch = int(N/batch_size)\n",
    "        for batch in range(n_batch):\n",
    "            if (batch+1) * batch_size > N:\n",
    "                batch_xs, batch_ys = X_train[batch*batch_size:], y_train_one_hot[batch*batch_size:]\n",
    "            else:\n",
    "                batch_xs, batch_ys = X_train[batch*batch_size:(batch+1)*batch_size], y_train_one_hot[batch*batch_size:(batch+1)*batch_size]    \n",
    "\n",
    "            sess.run(optimizer, \n",
    "                     feed_dict={XX: batch_xs, \n",
    "                                Y1: batch_ys[:,0:2], \n",
    "                                Y2: batch_ys[:,2:4],\n",
    "                                Y3: batch_ys[:,4:6],\n",
    "                                Y4: batch_ys[:,6:8], \n",
    "                                Y5: batch_ys[:,8:10],\n",
    "                                Y6: batch_ys[:,10:12]\n",
    "                               })\n",
    "\n",
    "        loss_val = sess.run(loss,\n",
    "                            feed_dict={XX: batch_xs, \n",
    "                                Y1: batch_ys[:,0:2], \n",
    "                                Y2: batch_ys[:,2:4],\n",
    "                                Y3: batch_ys[:,4:6],\n",
    "                                Y4: batch_ys[:,6:8], \n",
    "                                Y5: batch_ys[:,8:10],\n",
    "                                Y6: batch_ys[:,10:12]\n",
    "                               })\n",
    "        print(\"Iter \" + str(epoch) + \"Testing loss=\" + str(loss_val))\n",
    "    y_pred = (sess.run(pred_label,feed_dict={XX: X_test}))\n",
    "    pred_prob= decode_one_hot(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57074504, 0.04853042, 0.26042379, 0.03144224, 0.03759398,\n",
       "       0.05126452])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64522165, 0.35477835, 0.48231593, 0.51768404, 0.481407  ,\n",
       "       0.518593  , 0.49741802, 0.5025821 , 0.49298292, 0.507017  ,\n",
       "       0.46970895, 0.530291  ], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([422.,  54., 176.,  28.,  32.,  49.], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.sum(decode_one_hot(y_test) , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([455., 455.,   0., 455.,   0., 455.], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pred_prob,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
